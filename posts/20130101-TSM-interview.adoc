= Interview with Peter Lawrey: High-Performance Systems in Java

Attila-Mihaly Balazs, Software Panther at Synapp.io, interviews Peter Lawrey, a Java consultant specializing in low-latency systems.

[Attila-Mihaly Balazs] Hello, everybody!
This is Attila for Today Soft Mag, and today I have with me Peter Lawrey.
Peter, thank you for agreeing to this interview, and we will talk about Java performance.
Could you please introduce yourself?

[Peter Lawrey] Yes, my name is Peter Lawrey.
I am a Java consultant in the low-latency space.
I have a popular blog called "Vanilla Java," which gets about 120,000 hits per month.
I also have a library called Chronicle, which is for low-latency persistence IPC and data store, and I'm third on StackOverflow for Java.

[Attila-Mihaly Balazs] When people think about low latency or high performance, they usually say things like "C++ is better." They phrase things in terms of the programming language.
How important do you think the programming language is, and what other factors influence the latency or throughput of the system besides the programming language?

[Peter Lawrey] What I found is that different programming languages can attract different development styles and developers.
In particular, if you've got a low-level language like C` or C and you don't have a pretty good understanding of exactly what's going on, you'll shoot yourself in the foot pretty quickly, and you'll learn fast-you have to.
Whereas in Java, a lot of developers are deliberately protected from needing to know all these details, and so often they don't, which is generally a good thing.
Except when you want to program in low latency, you need to have a much better understanding of what the code is really doing.
It's not that Java can't do it; it's more that there aren't as many Java developers with that skill set.
In C`, you're kind of forced to have that skill set-you won't survive if you don't.
The libraries can make a difference as well, but the biggest advantage for Java is the fact that so many of the common libraries you're likely to need are built-in, whereas in C++ you have to go to third-party libraries to do a lot of the same things.

[Attila-Mihaly Balazs] So, do you find that the general opinion that C++ is faster, or that compiled languages are faster than Java, holds up, or is this just a myth?

[Peter Lawrey] In theory, C` is always faster-in theory.
The thing is that in practice, you have limited resources, limited time, limited expertise, and changing requirements.
In that sort of environment, what can happen is that you don't have enough time to micro-optimize every little bit; you can't fine-tune everything because data becomes unmaintainable.
So, given, let's say, a week or a month, a developer who's reasonably equally skilled in both languages will produce much the same performance.
It's just that if you give that same developer a year instead to do the same task, it will be faster in C`.
When you see the libraries that are particularly faster in C` and C, they are well-understood problems that don't change very much and have been really tuned to death-things like video processing, matrix operations, the sort of operations that have been around for a very long time, involve huge pulses, simple code repeated many times.
In those situations, you find that C is faster.
But in most business-related applications, the amount of code fine-tuning you can do on each line isn't as important as the overall performance of your application.
Business logic tends to change over time, and then what you tend to think about is maintainability.
Once that starts coming in, and robustness, and you face lots of changes, then you have to back off in C` anyway.
You end up building a lot of the protections that Java gives you already.
You end up having some sort of message brokering system to isolate the components of your system, to protect from crashes, for example-all those sorts of things Java will do for you efficiently.
So there's no guarantee that the C` systems would be faster.
In particular, I worked in one place where all of the client-facing application was written in C`, and that was the less latency-sensitive, whereas the hedging of all of the funds, the latency-sensitive code, was written in Java because we had a much faster time to market.
In fact, a lot of the fast delivery, a lot of the new changes, were going into the Java system simply because the C++ had reached the point where it was very difficult to maintain.
They would print, for example, daily crash reports.
Instead of throwing exceptions, the whole program would crash and restart-all those sorts of things that would be considered unacceptable in Java.

[Attila-Mihaly Balazs] Interesting.
So what advice would you give somebody who is a Java programmer and is just starting to get interested in the performance of their system?
Maybe they are interested themselves, or maybe there is an external reason, like the client is saying that the system is too slow.
What would be the first steps they should take?

[Peter Lawrey] The most useful thing is visibility: what is going on in your system, where is the time being spent.
Using things like profilers is a first step to look across your whole application.
But then, once you feel you have an understanding of what your application is doing, putting timestamps in and recording those, either logging them or using something like my Chronicle to record them in a low-latency way, gives you visibility into what the application is doing.
It allows you to see where your time is being lost, what it is doing, and then the simple problems you can solve-you break those down and make them faster and faster.
The way I got into the low-latency space is that I initially started with a company that wasn't particularly low-latency, but I had this aim of making the system ten times faster than it needed to be.
Then for the next client, the next people I worked for, I did the same thing, again and again.
Eventually, I moved from hundreds of milliseconds down into the hundreds of microseconds and eventually the sub-hundred microsecond range.
So, you can do it in a stepwise fashion, but I generally find that if you make a system that can handle ten times the volume that is actually asked for, it's usually very stable as well.
So, there are benefits to doing this; you're not just doing the absolute minimum all the time.

[Attila-Mihaly Balazs] Good.
So, Peter, what is your favorite thing about Java, either the language or the platform?

[Peter Lawrey] My favorite thing about Java is just that it has so much of what you need built-in, and the toolset is very good and mature.
There are a lot of cooler new languages out there, but they don't have good profilers and debuggers and a lot of the toolset around to help you write the code and code analysis.
It's really the toolset that brings Java to life, so to speak, rather than just the language itself.
Part of the reason why there is such a good toolset is that Java is such a poor-feature language, in the sense that it's very economical in terms of what features it adds.

[Attila-Mihaly Balazs] Great.
Java 8 is coming up and it should be launched this autumn, I think.
Are there any particular features of Java 8 which you are excited about?

[Peter Lawrey] I think the most exciting thing about it is that there are a lot of features being added-not huge ones in themselves, but a lot of improvements.
Closures is the one that gets the most press, although technically it's really just catching up with C#.
They couldn't agree on what specifications they should have for closures, so they eventually settled on what C# does.
They added virtual extensions, which internally are called something else, I can't remember, but why did they call it "virtual extensions"?
Well, that's what C# calls them.

So, in a way, it's really just catching up with what other languages are doing.
But a lot of the other features-there are 66 improvements, of which 3 relate to closures-a lot of them are smaller improvements, but you see quite a lot of development in the evolution of the JVM.
Things such as Joda-Time's `DateTime` being brought into the language-it's probably one of the most popular add-ons till now-to be able to use a proper `DateTime`.
For me, at the lower level, it's things like having proper discrete memory barriers.

So `Unsafe` has a force load/force store memory barrier that's explicit.
In the past, you sort of had to do it indirectly by using other operations that also had these features, whereas now you can deal with them explicitly.
But that's a very low-level feature.

[Attila-Mihaly Balazs] Are there any features which you would like to see in Java and are not included in Java 8?

[Peter Lawrey] Probably the biggest thing that I would like to see improved is related to `Unsafe`, which I use quite a lot.
It's not about adding features but actually making them part of the specification.
There's a lot of functionality in `Unsafe` that's used in Chronicle, Disruptor, and other libraries, which are outside the specifications.
They're there in OpenJDK and HotSpot and other compatible JVMs such as JRocket or Azul Zing, but they're not standards.

They wouldn't need to do anything in terms of adding functionality; they would just need to make it a standard feature of all Java platforms.
That way, you'd have a standard way of dealing with low-level memory access in a thread-safe manner.

[Attila-Mihaly Balazs] Are there any resources like books, blogs, videos, or training courses that you would recommend to Java programmers who are interested in the domain of performance?
There is, of course, your blog, which you mentioned in the beginning, and we will link to that, but what other resources would you recommend?

[Peter Lawrey] I would recommend looking at the Performance Java User's Group because that's where I put what I consider the most interesting video posts on the subject, and I hope to encourage other people to post there as well.
So, I think that's probably the best place to start.

There are two other blogs-well, not really blogs, but forums and email groups-that are worth looking at:

* `Mechanical Sympathy` is led by Martin Thompson, who was the CTO at LMAX when the Disruptor was developed.
It's very low-level, though.
Even most people who are interested in Java performance wouldn't have use for about 99% of it, but it's a very interesting discussion all the same.
* `Friends at jClarity`, led by Benjamin Evans and Martijn Verburg, focuses on GC and related issues.
They provide practical advice, consulting, and even some products in this space.
Their forum is very interesting if you're looking to tune your garbage collection.

[Attila-Mihaly Balazs] Great.
We will include links to all these in the comments section and annotations for this video.
Is there anything else you would like to talk about, related to this?

[Peter Lawrey] Yes, I've got a new version of Chronicle coming up, which is added to a new organization on GitHub called OpenHFT.
It's a set of open high-frequency trading-based libraries.
Chronicle itself is being split into sections: memory manipulation and deserialization will be separated from its logging capabilities.
This means you don't have to use logging to disk to use its features.

It's also been made more performant.
For example, on this laptop, I can get 80 million messages a second passed from one thread to another, and that's with every message being persisted.
Additionally, it will have support for rolling logs.
While you could implement this yourself in Chronicle 1, a lot of people wanted the library to handle it, and that's going to be a feature added in Chronicle 2.

There's also another library being developed to store huge amounts of data off-heap, particularly into memory-mapped files.
It will provide features similar to Terracotta's BigMemory, but instead, it's only limited by the size of your disk space rather than your main memory.
This allows for much larger capacities and more efficient data storage, so you can get data in and out faster and use less space.

Finally, there's a fix engine coming up, which will also be based on Chronicle.
It will allow for low-latency parsing and writing of fix messages.
It will be loosely based on what QuickFix does, but it's designed to be much more efficient.
